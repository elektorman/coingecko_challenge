{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8dWIh+PKf2PCm4AJAlbrq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INSTALAR PYSPARK\n",
        "- Java (JVM) es requerido para iniciar una Spark Session"
      ],
      "metadata": {
        "id": "hdFTNELGzXTx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcuA6RP7yJ2Y"
      },
      "outputs": [],
      "source": [
        "# Instalar JVM con el shell command:\n",
        "!java -version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar PYSPARK\n",
        "!pip install pyspark\n"
      ],
      "metadata": {
        "id": "UHTh76gxzagC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INICIALIZAR una SPARK SESSION"
      ],
      "metadata": {
        "id": "ZNqSmzsL0U2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "-lxvQLjq0P7f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "                    .appName(\"coingecko_challenge\") \\\n",
        "                    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "1V5FJkxm1K1V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check de SparkSession\n",
        "print(f\"Spark version: {spark.version} \\nAppName: \\\"{spark.sparkContext.appName}\\\" \\nBy: Hector Cruz\")"
      ],
      "metadata": {
        "id": "9zKgJa-v-d9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LEER ARCHIVO FUENTE\n",
        "\n",
        "## NOTAS:\n",
        "- Cargar el archivo fuente \"btc_challenge.csv\" en la sesion activa del Notebook en Google Colab\n",
        "\n",
        "- O bien, conectar directamente a la carpeta en Drive ejecutando el siguiente codigo:\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZUZl9I9E3QxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir SCHEMA\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, DateType\n",
        "from pyspark.sql.functions import col, current_timestamp\n",
        "\n",
        "btc_schema = StructType([\n",
        "                            StructField(\"date\", dataType= StringType()),\n",
        "                            StructField(\"vol\", dataType= DoubleType()),\n",
        "                            StructField(\"open\", dataType= DoubleType()),\n",
        "                            StructField(\"high\", dataType= DoubleType()),\n",
        "                            StructField(\"low\", dataType= DoubleType()),\n",
        "                            StructField(\"close\", dataType= DoubleType())\n",
        "                          ])\n",
        "\n"
      ],
      "metadata": {
        "id": "tq6HjeBq3V6r"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LEER ARCHIVO FUENTE\n",
        "btc_df = spark.read \\\n",
        "                .option(\"header\", True) \\\n",
        "                .schema(btc_schema) \\\n",
        "                .csv(\"/content/btc_challenge.csv\")"
      ],
      "metadata": {
        "id": "yO8veBt_QTgi"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_df.printSchema()"
      ],
      "metadata": {
        "id": "zzmEtZ-ZOMiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK DE LECTURA\n",
        "btc_df.show(5)"
      ],
      "metadata": {
        "id": "Pcd-j-zsHCal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPARACION DE DATOS"
      ],
      "metadata": {
        "id": "D5y43jy8rh6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiar fecha a tipo DATE:\n",
        "from pyspark.sql.functions import to_date, col\n",
        "\n",
        "btc_date_df = btc_df.withColumn(\"date\", to_date(col(\"date\"), \"dd-MM-yyyy\")  )\n"
      ],
      "metadata": {
        "id": "DErqN7zPDOWE"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check de modificación\n",
        "btc_date_df.printSchema()"
      ],
      "metadata": {
        "id": "TI9m9DjNJbJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check de modificación 2\n",
        "btc_date_df.show(5)"
      ],
      "metadata": {
        "id": "eRdx0ZvzHokD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregar campo 'MES' (Opcional para check de agregaciones)\n",
        "from pyspark.sql.functions import date_format\n",
        "\n",
        "btc_month_df = btc_date_df.withColumn(\"mes\", date_format(\"date\", \"MM\") )\n"
      ],
      "metadata": {
        "id": "f-vWjajiON2Q"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_month_df.printSchema()"
      ],
      "metadata": {
        "id": "OJneRjkfPsPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check de modificación\n",
        "btc_month_df.show(5)"
      ],
      "metadata": {
        "id": "eLBRDYXGPvNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check de aggregacion\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "btc_month_df.groupBy(\"mes\").agg( sum(\"close\") ).show()"
      ],
      "metadata": {
        "id": "5Q0sVoN6RTEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WINDOW FUNCTIONS"
      ],
      "metadata": {
        "id": "zX4VHgbUskat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RANK\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import sum, desc, rank\n",
        "\n",
        "\n",
        "win_spec = Window.partitionBy(\"mes\").orderBy( desc(\"close\") )  #.orderBy( desc(\"metric\")\n",
        "btc_win_df = btc_month_df.withColumn(\"rank\", rank().over(win_spec))\n"
      ],
      "metadata": {
        "id": "RL8CpMelRS-0"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_win_df.show(10)"
      ],
      "metadata": {
        "id": "V3vJbv0E79O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MOVING AVG\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "ma_7d = Window.orderBy(\"date\").rowsBetween(start=-6, end=0)\n",
        "ma_14d = Window.orderBy(\"date\").rowsBetween(start=-13, end=0)\n",
        "ma_30d = Window.orderBy(\"date\").rowsBetween(start=-29, end=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "oSTL_a8ae7Nb"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_ma_df = btc_month_df.withColumn(\"7day_avg\", avg(\"close\").over(ma_7d)) \\\n",
        "                        .withColumn(\"14day_avg\", avg(\"close\").over(ma_7d)) \\\n",
        "                        .withColumn(\"30day_avg\", avg(\"close\").over(ma_7d)) \\\n",
        "                        .select([\"date\", \"open\", \"close\", \"7day_avg\", \"14day_avg\", \"30day_avg\"])\n",
        "btc_ma_df.show(40)"
      ],
      "metadata": {
        "id": "XiS6iWGje7Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QESXxu_me7Eo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}